---
title: 'AI Mediated Mediocrity'
date: 2025-12-14
permalink: /posts/2025/12/ai_mediated_mediocrity/
tags:
  - AI
  - Prodcutivity
  - Research
---

The first time I talked to ChatGPT, it blew my mind. Talking to a computer. Getting real answers. Learning something. It was life-changing. It pushed me, a dropout, back into school for computer science.

More than that, it gave me a new dream when my old one died. The pursuit to understand intelligence. To improve the world.

On that journey, language models became mentors, teammates, friends. I spent hundreds of hours talking to them. I read textbooks, did research, even gave lectures in my school's AI club. Now, I finally know enough to see limitations I was blind to at first.

Here's the core problem: LLMs are excellent at removing struggle. And struggle is where growth happens.

**Take coding.** LLMs make it easy to get unstuck. Too easy. I'm a decent coder. But I'd be better if I struggled more. Using LLMs helped me move fast, keep a 4.0, and still live my life. But it also robbed me of hard moments I should have sat with. Moments where understanding solidifies.

I don't regret using them. But I wish I made more of a habit of using them as tutors rather than laborers.

So I'm changing my approach. I'm allocating more time for long, uninterrupted coding blocks. Sitting with confusion. Reading the docs. Using LLMs only for small, narrow questions. Moving slower. Growing faster.

**Take idea generation.** LLMs are even more disabling here. Ideas don't arrive clean. They start ugly. They take work. When I ask an LLM for good ideas, I circumvent that. I get something polished but not my own. Presentable but dead.

Your ideas have to come from you. If you want better ideas, focus on improving your mind, not your tools. Good tools can help shape ideas. They can't have them for you. Think more. Write more. That's what I'm resolving to do. Letting ideas surface on their own. No assistant. Just me and my text editor.

**Take research.** Same pattern, worse consequences. I've been doing research for a year now. During that time, I've leaned a lot on LLMs to think with, to plan, to code. The code was often wrong. The ideas were often flat. I chased bad directions for months at time. I blame a combination of poor prompting on my part, and terrible sycophancy on the LLMs'. 

LLMs haven't made me a better researcher. But they did make me feel like one; at my own expense.

So I'm pulling back. I'm spending my winter break going AI-minimal. Me, my mind, and my keyboard. Nothing external until I've tried and failed alone.

I'm not anti-AI. I just want more agency. LLMs are good for particular things. They're leverage amplifiers. But right now, I don't need to expand my leverage. I need to expand my competence. 

My prediction for these three weeks: less output, more learning, more clarity. That's a trade I'm willing to make.